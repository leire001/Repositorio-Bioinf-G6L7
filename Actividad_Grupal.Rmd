---
title: "Actividad 3"
author: "Joana Mercado, Leire Irusta, Miquel Bovea, David Sanz, Daniel Domínguez"
date: "2025-01-14"
output: html_document
---

```{r setup, include=TRUE}
setwd("~/ruta/al/repositorio")

#Librerías necesarias

library(dplyr)
library(caret)
library(randomForest)
library(ggplot2)
library(e1071)  
library(rpart)  
library(rpart.plot) 
library(rattle) 
library(stats)
library(Rtsne)
library(cluster) 
library(factoextra)
library(ggdendro)


# Cargamos los encabezados del dataframe desde el archivo column_names.txt

encabezados <- readLines("column_names.txt")

# Cargamos los datos desde el archivo gene_expression.csv

datos <- read.csv("gene_expression.csv", header = FALSE, sep = ";")

# Asignamos los encabezados al dataframe

colnames(datos) <- encabezados

# Guardamos el dataframe con encabezados en un nuevo archivo CSV

write.csv(datos, "datos_combinados.csv", row.names = FALSE)
data <- read.csv("datos_combinados.csv")

# Cargamos las etiquetas de los datos (no tienen encabezados, por lo que se lo añadimos)

encabezado_clases <- c("Sample", "Class")
clases <- read.csv('classes.csv', header = FALSE, sep = ";")
colnames(clases) <- encabezado_clases

#Al observar los datos vemos que algunos genes tienen 0 expresión en todas las muestras, por lo que eliminamos las columnas con valor 0 que no aportan información

sumas <- colSums(data) # sumo los datos por columnas
columnascero <- names(sumas[sumas==0]) # veo cuantas sumas son == 0
data2 <- data[, !names(data) %in% columnascero] # reemplazo el dataset df sin esas columnas

#Incluimos la columna de la clase de cada muestra y escalamos los datos
df <- cbind(clases["Class"],scale(data2))

#Asignamos el ID de cada muestra al nombre de cada fila
rownames(df) <- clases$Sample
```

```{r MDS}

#Reducimos la dimensionalidad mediante el método MDS
#Primero calculamos la matriz de las distancias euclidias
distancias<- dist(df, method = "euclidean")

#Usamos la función mcdscale para realizar el MDS
mdsresults<-cmdscale(distancias, eig = TRUE, k=2)

#Calculamos la varianza explicada
varianza<-mdsresults$eig/sum(mdsresults$eig)*100

#Pasamos a df los datos 
mds.df<-data.frame(mdsresults$points)
colnames(mds.df) <- c("Dim1", "Dim2")

#Graficamos    
mds.df$Class<-clases$Class

library(ggplot2)
ggplot(mds.df, aes(x=Dim1, y=Dim2, color= Class))+
  geom_point(size=2)+
  scale_color_manual(values = c("red", "green", "yellow", "blue", "purple"))+
  labs(title = "MDS", x = "D1", y = "D2")
theme_minimal()

```

```{r t-SNE}
#Realizamos la técnica t-SNE de reducción de dimensionalidad.
library(Rtsne)
#En primer lugar creamos un df sólo con datos numéricos

df.numerico <- df[, sapply(df, is.numeric)]

#Ahora hay que crear una matriz con los datos

matriz<-as.matrix(df.numerico)

#Hay que usar una semilla de aleatorización para que sea reproducible
set.seed(142)

#Añadimos el código
tsne<-Rtsne(X=df.numerico)
tsne_result <- Rtsne(matriz, dims = 2, perplexity = 20, verbose = TRUE, max_iter = 500)

#Creamos un data frame con los resultados anteriores

tsne_df<-as.data.frame(tsne_result$Y)
colnames(tsne_df)<-c("Dim1", "Dim2")
tsne_df$Class<-df$Class

#Graficamos

ggplot(tsne_df, aes(x=Dim1, y=Dim2, colour = Class))+
  geom_point(size=1)+
  scale_color_manual(values = c("red", "green", "yellow", "blue", "purple"))+
  labs(title ="t-SNE", x="Dimensión 1", y="Dimensión 2")+
  theme_minimal()


```


```{r training split}
#Vamos a clasificar por tipo de tumor (AGH, CFB, CGC, CHC y HPB)

table(df$Class)

df$Class <- as.factor(df$Class)

#Vamos a sembrar una semilla y dividir el set para el entrenamiento

set.seed(1998)
trainIndex <- createDataPartition(df$Class, p = 0.8, list = FALSE)
trainData <- df[trainIndex,]
testData <- df[-trainIndex,]

# Convertir la variable objetivo en factor (si no lo está)
train_data$Class <- as.factor(train_data$Class)
test_data$Class <- as.factor(test_data$Class)
```

```{r clustering no jerarquico: k-means}

# Nota: para poder realizar los clusterings se han los datos pero sin los nombres de las clases:

df_scaled <- scale(data2)

# A continuación, aparece el código para la implementación del clustering no jerárquico K-means:

kmeans.result <- kmeans(df_scaled, centers = 2, iter.max = 500, nstart = 25)
fviz_cluster(kmeans.result, df_scaled, xlab = '', ylab = '') +
  ggtitle("Cluster plot, centers = 2", subtitle = "") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, margin = margin(b = -10)))

# Para conocer cuál es el número óptimo de k se realiza la siguiente función:

fviz_nbclust(data2, kmeans, method = "wss") +
  ggtitle("optimal number of clusters", subtitle = "") +
  theme_classic()

```

```{r clustering jerarquico aglomerativo: Ward's Linkage}

# Implementación del clustering aglomerativo:

# Primero hay que calcular la distancia de la matriz:

dist_matrix <- dist(df_scaled)

# Hay que ejecutar el algoritmo de clusterización jerárquica aglomerativa "varianza mínima de Ward":

hclust_model_ward <- hclust(dist_matrix, method = "ward.D")

colors <- rainbow(5)
clust_ward <- fviz_dend(hclust_model_ward, 
                        cex = 0.5,
                        k = 5,
                        palette = colors,
                        main = "Ward",
                        xlab = "Índice de Observaciones",
                        ylab = "Distancia") + 
  theme_classic()

df$cluster_ward <- as.factor(cutree(hclust_model_ward, k = 5))

# Para poder obtener el gráfico con el dendograma se ejecuta la siguiente función:

plot(clust_ward, main = "Ward's Linkage")

```

```{r random forest}
modelLookup(model = "rf")

set.seed(1998)
rfModel <- train(Class ~ .,
                 data = trainData,
                 method = "rf",
                 trControl = trainControl(method = "cv", number = 10),
                 tuneLength = 10,
                 prob.model = TRUE)
rfModel

plot(rfModel)

predictionsrf <- predict(rfModel, newdata = testData, type = "raw")

CMrf <- confusionMatrix(predictionsrf, testData$Class)

# Imprimimos la matriz de confusión
print(CMrf)

# Extraemos las métricas de precisión, sensibilidad, recall y calculamos F1-score para cada clase 

precision <- CMrf$byClass[, "Pos Pred Value"] 
recall <- CMrf$byClass[, "Sensitivity"]      
especificidad <- CMrf$byClass[,"Specificity"]
f1_scores <- 2 * (precision * recall) / (precision + recall)

# Mostramos las métricas de sensibilidad, especificidad, precisión y F1-Score por clase

cat("Precisión:\n")
print(precision)
cat("Recall (sensibilidad):\n")
print(recall)
cat("Especificidad:\n")
print(especificidad)
cat("F1-Score:\n")
print(f1_scores)
```

```{r SVM}

# Entrenar el modelo SVM
set.seed(1998)  
svm_model <- svm(Class ~ ., data = train_data, kernel = "linear", scale = TRUE)

# Ver un resumen del modelo
summary(svm_model)

## Realizar predicciones

# Predicción en el conjunto de prueba
predictions <- predict(svm_model, test_data)

# Crear matriz de confusión
library(caret)
confusion_mat <- confusionMatrix(predictions, test_data$Class)

# Mostrar matriz de confusión
print(confusion_mat)

# Extraer métricas clave
accuracy <- confusion_mat$overall["Accuracy"]      # Precisión
precision <- confusion_mat$byClass["Precision"]    # Precisión por clase
recall <- confusion_mat$byClass["Recall"]          # Sensibilidad
specificity <- confusion_mat$byClass["Specificity"]  # Especificidad
f1_score <- 2 * (precision * recall) / (precision + recall)  # Score F1

# Mostrar métricas
cat("Precisión (Accuracy): ", accuracy, "\n")
cat("Precisión (Precision): ", precision, "\n")
cat("Sensibilidad (Recall): ", recall, "\n")
cat("Especificidad: ", specificity, "\n")
cat("Score F1: ", f1_score, "\n")

## Visualizar la separación de clases

# Graficar con ggplot2
library(ggplot2)
train_data$Prediction <- predict(svm_model, train_data)

ggplot(train_data, aes(x = train_data[, 2], y = train_data[, 3], color = Prediction)) +
  geom_point(size = 2) +
  labs(title = "Separación de Clases por SVM", x = "Variable 1", y = "Variable 2") +
  theme_minimal()

##.Guardar los resultados

# Guardar el modelo SVM
saveRDS(svm_model, "svm_classification_model.rds")

# Guardar la matriz de confusión
write.csv(as.table(confusion_mat), "confusion_matrix.csv", row.names = TRUE)

```



```{r decission tree}

### Método Decission Tree ###

modelLookup(model = "rpart") # Vemos si este método es útil para Regresión y para Clasificación.

set.seed(1998)

dtModel <- train(Class ~.,
                 data = trainData,
                 method = "rpart",
                 trControl = trainControl(method = "cv", number = 10),
                 preProcess = c("center", "scale"),
                 tuneLength = 10)
dtModel

plot(dtModel)

fancyRpartPlot(dtModel$finalModel, type=4)

predictions_dt <- predict(dtModel, newdata = testData, type = "raw")

# Matriz de confusión del modelo Decission Tree

CM_dt <- confusionMatrix(predictions_dt, testData$Class)

# Mostramos la matriz de confusión

print(CM_dt)

# Extraemos las métricas de precisión, sensibilidad, especifidad y F1-score

precision_dt <- CM_dt$overall["Accuracy"] # Precisión del método Decission Tree
print(precision_dt)

sensibilidad_dt <- CM_dt$byClass[, "Sensitivity"] # Sensibilidad
print(sensibilidad_dt)

especificidad_dt <- CM_dt$byClass[,"Specificity"] # Especifidad
print(especificidad_dt)

f1_score_dt <- 2 * (precision_dt * sensibilidad_dt) / (precision_dt + sensibilidad_dt) # F1-score
print(f1_score_dt)

# Mostramos las métricas 

cat("Precisión (Accuracy): ", precision_dt, "\n")
cat("Sensibilidad: ", sensibilidad_dt, "\n")
cat("Especificidad: ", especificidad_dt, "\n")
cat("Score F1: ", f1_score_dt, "\n")

```
