#Preparar el entorno de trabajo

# 1) Cargar los paquetes
library(e1071)   # Para SVM
library(caret)   # Para métricas y partición de datos
library(dplyr)   # Para manipulación de datos

# 2) Cargar y depurar los datos
# Cargamos los encabezados del dataframe desde el archivo column_names.txt

encabezados <- readLines("column_names.txt")

# Cargamos los datos desde el archivo gene_expression.csv

datos <- read.csv("gene_expression.csv", header = FALSE, sep = ";")

# Asignamos los encabezados al dataframe

colnames(datos) <- encabezados

# Guardamos el dataframe con encabezados en un nuevo archivo CSV

write.csv(datos, "datos_combinados.csv", row.names = FALSE)
data <- read.csv("datos_combinados.csv")

# Cargamos las etiquetas de los datos (no tienen encabezados, por lo que se lo añadimos)

encabezado_clases <- c("Sample", "Class")
clases <- read.csv('classes.csv', header = FALSE, sep = ";")
colnames(clases) <- encabezado_clases

#Al observar los datos vemos que algunos genes tienen 0 expresión en todas las muestras, por lo que eliminamos las columnas con valor 0 que no aportan información

sumas <- colSums(data) # sumo los datos por columnas
columnascero <- names(sumas[sumas==0]) # veo cuantas sumas son == 0
data2 <- data[, !names(data) %in% columnascero] # reemplazo el dataset df sin esas columnas

#Incluimos la columna de la clase de cada muestra y escalamos los datos
df <- cbind(clases["Class"],scale(data2))

#Asignamos el ID de cada muestra al nombre de cada fila
rownames(df) <- clases$Sample

#3. Imputación de valores faltantes
# Verificar si hay valores NA en el dataframe
sum(is.na(df))

#4. Dividir los datos en entrenamiento y prueba

# Dividir datos en entrenamiento y prueba
set.seed(1998)  # Para reproducibilidad
train_index <- createDataPartition(df$Class, p = 0.8, list = FALSE)

# Crear conjuntos de entrenamiento y prueba
train_data <- df[train_index, ]
test_data <- df[-train_index, ]

#5. Entrenar el modelo SVM clasificación

# Convertir la variable objetivo en factor (si no lo está)
train_data$Class <- as.factor(train_data$Class)
test_data$Class <- as.factor(test_data$Class)

# Entrenar el modelo SVM
svm_model <- svm(Class ~ ., data = train_data, kernel = "linear", scale = TRUE)

# Ver un resumen del modelo
summary(svm_model)

#6. Realizar predicciones

# Predicción en el conjunto de prueba
predictions <- predict(svm_model, test_data)

# Crear matriz de confusión
library(caret)
confusion_mat <- confusionMatrix(predictions, test_data$Class)

# Mostrar matriz de confusión
print(confusion_mat)

# Extraer métricas clave
accuracy <- confusion_mat$overall["Accuracy"]      # Precisión
precision <- confusion_mat$byClass["Precision"]    # Precisión por clase
recall <- confusion_mat$byClass["Recall"]          # Sensibilidad
specificity <- confusion_mat$byClass["Specificity"]  # Especificidad
f1_score <- 2 * (precision * recall) / (precision + recall)  # Score F1

# Mostrar métricas
cat("Precisión (Accuracy): ", accuracy, "\n")
cat("Precisión (Precision): ", precision, "\n")
cat("Sensibilidad (Recall): ", recall, "\n")
cat("Especificidad: ", specificity, "\n")
cat("Score F1: ", f1_score, "\n")

#8. Visualizar la separación de clases

# Graficar con ggplot2
library(ggplot2)
train_data$Prediction <- predict(svm_model, train_data)

ggplot(train_data, aes(x = train_data[, 2], y = train_data[, 3], color = Prediction)) +
  geom_point(size = 2) +
  labs(title = "Separación de Clases por SVM", x = "Variable 1", y = "Variable 2") +
  theme_minimal()

#9.Guardar los resultados

# Guardar el modelo SVM
saveRDS(svm_model, "svm_classification_model.rds")

# Guardar la matriz de confusión
write.csv(as.table(confusion_mat), "confusion_matrix.csv", row.names = TRUE)
